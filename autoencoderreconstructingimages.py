# -*- coding: utf-8 -*-
"""AutoEncoderReconstructingImages.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12p4OVJjeqJyUgvO6yFaKxUjlj-iFBky2
"""

!pip install tensorflow

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, losses
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Model

import tensorflow_datasets as tfds
import numpy as np
import tensorflow as tf

# Load dataset
dataset, info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)

# Function to extract images and convert to NumPy
def dataset_to_numpy(ds):
    images = []
    for img, _ in tfds.as_numpy(ds):
        img = tf.image.resize(img, (128, 128))  # or 224x224
        img = img.numpy().astype('float32') / 255.  # normalize
        images.append(img)
    return np.array(images)

# Convert train and test sets
x_train = dataset_to_numpy(dataset['test'])
x_test = dataset_to_numpy(dataset['train'])

print(x_train.shape)
print(x_test.shape)

x_train[0].shape

#afficher l'image
plt.imshow(x_train[0], cmap='gray')

class Autoencoder(Model):
  def __init__(self, latent_dim, shape):
    super(Autoencoder, self).__init__()
    self.latent_dim = latent_dim
    self.shape = shape
    self.encoder = tf.keras.Sequential([
      layers.Flatten(), #28*28
      layers.Dense(latent_dim, activation='relu'),
    ])
    self.decoder = tf.keras.Sequential([
      layers.Dense(tf.math.reduce_prod(shape).numpy(), activation='sigmoid'),
      layers.Reshape(shape)
    ])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded


shape = x_test.shape[1:]
latent_dim = 64
#Initialisation du modele
autoencoder = Autoencoder(latent_dim, shape)

autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())

autoencoder.fit(x_train, x_train,
                epochs=5,
                shuffle=True,
                validation_data=(x_test, x_test))

"""testing it with encoding decoding images from the test set"""

encoded_imgs = autoencoder.encoder(x_test).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()

encoded_imgs.shape #taille de l'espace latent 64

decoded_imgs.shape

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
  # display original
  ax = plt.subplot(2, n, i + 1)
  plt.imshow(x_test[i])
  plt.title("original")
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # display reconstruction
  ax = plt.subplot(2, n, i + 1 + n)
  plt.imshow(decoded_imgs[i])
  plt.title("reconstructed")
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
plt.show()



"""## Reconstructing masked images"""

import tensorflow_datasets as tfds
import tensorflow as tf
import numpy as np

# 1. Load Oxford Flowers 102
dataset, info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)

# 2. Convert to grayscale, resize, normalize
def preprocess(ds):
    images = []
    for img, _ in tfds.as_numpy(ds):
        img = tf.image.resize(img, (128, 128))                   # Resize to 128x128
        # img = tf.squeeze(img, axis=-1)                           # Remove (H, W, 1) -> (H, W)
        img = img.numpy().astype('float32') / 255.0              # Normalize to [0, 1]
        images.append(img)
    return np.array(images)

x_train = preprocess(dataset['test'])      # Shape: (6149, 128, 128)
x_test = preprocess(dataset['train'])        # Shape: (1020, 128, 128)

x_train.shape

# 3. Apply hard masking
def apply_random_masking(x_data, mask_ratio=0.3):
    mask = np.random.binomial(1, 1 - mask_ratio, size=x_data.shape).astype('float32')
    return x_data * mask

x_train_masked = apply_random_masking(x_train, mask_ratio=0.3)
x_test_masked = apply_random_masking(x_test, mask_ratio=0.3)

# 4. (Optional) Add channel dimension for model input: (N, H, W, 1)
x_train = np.expand_dims(x_train, axis=-1)
x_test = np.expand_dims(x_test, axis=-1)
x_train_masked = np.expand_dims(x_train_masked, axis=-1)
x_test_masked = np.expand_dims(x_test_masked, axis=-1)

x_train.shape

x_train_masked.shape

x_test_masked.shape

import tensorflow as tf
from tensorflow.keras import layers, Model

class Decoder(Model):
    def __init__(self):
        super(Decoder, self).__init__()

        # --- Encoder ---
        self.encoder = tf.keras.Sequential([
            layers.Input(shape=(128, 128, 3)),
            layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2),
            layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2),
            layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),
        ])

        # --- Decoder ---
        self.decoder = tf.keras.Sequential([
            layers.Conv2DTranspose(16, (3, 3), strides=2, activation='relu', padding='same'),
            layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same'),
            layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same'),
            layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')  # Output shape: (128, 128, 3)
        ])

    def call(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# Create and compile the model
autoencoder = Decoder()
autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())

autoencoder.fit(
    x_train_masked, x_train,
    epochs=5,
    shuffle=True,
    validation_data=(x_test_masked, x_test)
)

autoencoder.encoder.summary()

autoencoder.decoder.summary()

encoded_imgs = autoencoder.encoder(x_test_masked).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):

    # display original + noise
    ax = plt.subplot(2, n, i + 1)
    plt.title("original + mask")
    plt.imshow(tf.squeeze(x_test_masked[i]))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    bx = plt.subplot(2, n, i + n + 1)
    plt.title("reconstructed")
    plt.imshow(tf.squeeze(decoded_imgs[i]))
    plt.gray()
    bx.get_xaxis().set_visible(False)
    bx.get_yaxis().set_visible(False)
plt.show()